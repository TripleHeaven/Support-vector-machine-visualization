import numpy as np
from sklearn.datasets import make_blobs
from sklearn.model_selection import train_test_split
from matplotlib import pyplot as plt
from sklearn.svm import LinearSVC
from sklearn.metrics import confusion_matrix


# n_samples - total number of points equally divided among clusters
# centers - The number of centers to generate
# random_state - random number generation for dataset creation
# cluster_std - The standard deviation of the clusters
X, y = make_blobs(n_samples=250, centers=2,
                  random_state=0, cluster_std=0.6)
# X is a set of points that are being generated by make_blobs
# y is a set of params of classification
# 0 and 1 
print(X)
print ('====')
print (y)
plt.scatter(X[:, 0], X[:, 1], c=y, cmap='winter')

#dividing our data into test and training sets
X_train, X_test, y_train, y_test = train_test_split(X, y)

# Linear Support Vector Classification
# C is regulazation param
# the strength of the regulazation
# is inversely proportional to C
# ???
svc = LinearSVC(C = 100)
svc.fit(X_train, y_train)

w = svc.coef_[0]
a = -w[0] / w[1]
def getXpointMin(setOfParams: list):
    forFinding=list()
    for elem in setOfParams:
        forFinding.append(elem[0])
    return min(forFinding)
def getXpointMax(setOfParams: list):
    forFinding=list()
    for elem in setOfParams:
        forFinding.append(elem[0])
    return max(forFinding)
xx = np.linspace(getXpointMin(X), getXpointMax(X))
yy = a * xx - svc.intercept_[0] / w[1]
plt.plot(xx, yy)


yy = a * xx - (svc.intercept_[0] - 1) / w[1]
plt.plot(xx, yy, 'k--')
yy = a * xx - (svc.intercept_[0] + 1) / w[1]
plt.plot(xx, yy, 'k--')


plt.show()

y_pred = svc.predict(X_test)
a = confusion_matrix(y_test,y_pred)
print (a)


